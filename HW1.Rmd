---
title: "DS HW1"
author: "Ruihan Ding"
date: "2026-02-25"
output: github_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r, echo = T, message = FALSE, results='hide', warning=FALSE}
library(ISLR)
library(glmnet)
library(caret)
library(tidymodels)
library(corrplot)
library(ggplot2)
library(plotmo)
library(ggrepel)
library(tidyverse)
```

Import the data.

```{r}
housing_train = 
  read_csv("housing_training.csv") |> 
  janitor::clean_names()

housing_test = 
  read_csv("housing_test.csv") |> 
  janitor::clean_names()
```

# a

(1) Fit a lasso model on the training data.

```{r}
ctrl1 = trainControl(method = "cv", number = 10)

set.seed(2026)
lasso.fit = train(sale_price ~ .,
                  data = housing_train,
                  method = "glmnet",
                  tuneGrid = expand.grid(alpha = 1, 
                                         lambda = exp(seq(8, 2, length = 100))),
                  trControl = ctrl1)
```

(2) Report the selected tuning parameter and the test error.

```{r}
plot(lasso.fit, xTrans = log)
lasso_lambda = lasso.fit$bestTune$lambda

lasso.pred = predict(lasso.fit, newdata = housing_test)
test_mse = mean((lasso.pred - housing_test[["sale_price"]])^2)
```

The selected tuning parameter is `r lasso_lambda`, and the test error is `r test_mse`.

(3) When the 1SE rule is applied, how many predictors are included in the model?

```{r}
ctrl_1se = trainControl(method = "cv",
                        number = 10,
                        selectionFunction = "oneSE")

set.seed(2026)
lasso_1se.fit = train(sale_price ~ .,
                      data = housing_train,
                      method = "glmnet",
                      tuneGrid = expand.grid(alpha = 1,
                                             lambda = exp(seq(8, 2, length = 100))),
                      trControl = ctrl_1se)

lasso_1se = lasso_1se.fit$bestTune$lambda
lasso_1se_coef = coef(lasso_1se.fit$finalModel, lasso_1se)
lasso_1se_coef
```

Under the 1SE rule, the model includes `r sum(lasso_1se_coef != 0) - 1` predictors.


# e

If R package “caret” was used for the lasso in (a), retrain this model using R package “glmnet”, and vice versa. Compare the selected tuning parameters between the two software approaches. Should there be discrepancies in the chosen parameters, discuss potential reasons for these differences.

```{r}
x = model.matrix(sale_price ~ ., housing_train)[,-1]
y = housing_train[["sale_price"]]

set.seed(2026)
cv.lasso = cv.glmnet(x, y, 
                     alpha = 1,
                     lambda = exp(seq(8, 2, length = 100)))
```

```{r}
plot(cv.lasso)
cv.lasso$lambda.min
```

```{r}
predict(cv.lasso, s = "lambda.1se", type = "coefficients")
```










